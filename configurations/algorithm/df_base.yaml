defaults:
  - base_pytorch_algo

x_shape: ${dataset.observation_shape}
z_shape: [512]
frame_stack: 1
data_mean: ${dataset.data_mean}
data_std: ${dataset.data_std}
external_cond_dim: 0 #${dataset.action_dim}
context_frames: ${dataset.context_length}
weight_decay: 1e-4
warmup_steps: 2000
gt_first_frame: 0.0
gt_cond_prob: 0.0 # setting this to 1 will give you teacher forcing + single frame diffusion
uncertainty_scale: 1
chunk_size: -1 # -1 for full trajectory diffusion, number to specify diffusion chunk size
calc_crps_sum: 100 # generate multiple samples for computing crps_sum
learnable_init_z: False
optimizer_beta: [0.9, 0.999]

diffusion:
  network_size: 32
  beta_schedule: cosine
  objective: pred_x0
  use_snr: False
  use_cum_snr: False
  snr_clip: 5.0
  cum_snr_decay: 0.9
  timesteps: 1000
  self_condition: False
  ddim_sampling_eta: 1.0
  p2_loss_weight_gamma: 0
  p2_loss_weight_k: 1
  schedule_fn_kwargs: {}
  sampling_timesteps: 50  # fixme, numer of diffusion steps, should be increased
  mask_unet: False
  num_gru_layers: 1
  num_mlp_layers: 0
  return_all_timesteps: False
  clip_noise: 20.0

schedule_matrix:
  actions: 2 # and positive --> [0,1] 3 and negative = [-1, 0, 1] in timedelta, etc. 
  positive_only: True
  build: False # whether to actually build the model -- set to true when training
  gamma: 0.99
  lam: 0.95
  clip_eps: 0.25
  entropy_beta: 0.01
  rollout_multiple: 1 # multiplier on how much farther beyond og pyramid height that we will allow rollouts
  max_roller: -1
  log_k_matrix: False
  k_matrix_log_every: 50
  k_matrix_batches: 1
  k_viz_max_steps: 150
  k_viz_summary_steps: [1, 5, 10, 25]
  raw_reward: True # always will be true
  raw_reward_crps: False
  step_reward: False 
  step_reward_crps: False
  difference_step_reward: False
  
  
